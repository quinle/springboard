{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db02af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a6b562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df_train = pd.read_csv('../processed data/df_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c03d4a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#D_* = Delinquency variables\n",
    "#S_* = Spend variables\n",
    "#P_* = Payment variables\n",
    "#B_* = Balance variables\n",
    "#R_* = Risk variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ccdd3",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65071aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns = ['S_2'])\n",
    "df_train = pd.get_dummies(df_train, columns = ['D_63', 'D_64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d03a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = df_train.columns.tolist()\n",
    "for i in ['D_63_CL',\n",
    " 'D_63_CO',\n",
    " 'D_63_CR',\n",
    " 'D_63_XL',\n",
    " 'D_63_XM',\n",
    " 'D_63_XZ',\n",
    " 'D_64_-1',\n",
    " 'D_64_0',\n",
    " 'D_64_O',\n",
    " 'D_64_R',\n",
    " 'D_64_U',\n",
    " 'target']:\n",
    "    columns_name.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718f2986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the StandardScaler to the numeric columns which are not dummy\n",
    "ct = ColumnTransformer([\n",
    "        ('somename', StandardScaler(), columns_name)\n",
    "    ], remainder='passthrough')\n",
    "scaled_df = ct.fit_transform(df_train)\n",
    "all_columns = df_train.columns\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af5e1c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train.target\n",
    "X = df_train.drop(columns = ['target'])\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0c7e26",
   "metadata": {},
   "source": [
    "MODELING PART: The metrics we use to evaluate performance is f1 score and confusion matrix. Assume that our goal is to predict as precisely as possible in both default and non-default case (i.e., we do not favor true positive nor true negative), we choose the following methods for our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc6ea89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179050e5",
   "metadata": {},
   "source": [
    "Method 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82a17692",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quinn/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/quinn/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/quinn/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/quinn/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/quinn/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/quinn/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/quinn/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/quinn/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/quinn/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/quinn/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7384672352995632"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "cross_val_score(lr, X_train, y_train, scoring=\"f1\", cv = 10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e33b6b",
   "metadata": {},
   "source": [
    "Method 2: Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7f8f2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6968165337948162"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "cross_val_score(gnb, X_train, y_train, scoring=\"f1\", cv = 10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629314f5",
   "metadata": {},
   "source": [
    "Method 3: LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3d62292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7358437451324035"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "cross_val_score(lda, X_train, y_train, scoring=\"f1\", cv = 10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d3d89b",
   "metadata": {},
   "source": [
    "Method 4: Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e13fe950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9214687500000001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "cross_val_score(rf, X_train, y_train, cv=10).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af49f9",
   "metadata": {},
   "source": [
    "Method 5: Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d25656a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7684923076923077"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()\n",
    "cross_val_score(gb, X_train, y_train, cv = 10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951182e",
   "metadata": {},
   "source": [
    "It seems that random forest performs the best, so we choose this model to tune. The most important hyperparameter to tune is number of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74368c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=0),\n",
    "                           {\n",
    "                              'max_features':np.arange(0.1,1.0,0.1)\n",
    "                            },cv=3, scoring=\"f1\",verbose=1,n_jobs=-1\n",
    "                           )\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d2e3ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ba9050",
   "metadata": {},
   "source": [
    "We now apply the model to test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc512080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8672869735553379"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(max_features = 0.2)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "769f5be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11374,   509],\n",
       "       [  575,  3542]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
